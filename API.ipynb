{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import googleapiclient.discovery\n",
        "import pandas as pd\n",
        "\n",
        "# Set your API key\n",
        "DEVELOPER_KEY = \"AIzaSyC0BmrSwtYtOnT78dBzgnbL3tp0RSpOwgg\"\n",
        "\n",
        "api_service_name = \"youtube\"\n",
        "api_version = \"v3\"\n",
        "\n",
        "youtube = googleapiclient.discovery.build(api_service_name, api_version, developerKey=DEVELOPER_KEY)\n",
        "\n",
        "# Initialize variables for pagination\n",
        "next_page_token = None\n",
        "comments = []\n",
        "\n",
        "while True:\n",
        "    request = youtube.commentThreads().list(\n",
        "        part=\"snippet\",\n",
        "        videoId=\"UZR1Vk1DQ24\",  # Replace with the video ID you want to retrieve comments from\n",
        "        maxResults=100,  # Adjust the number of comments per page as needed\n",
        "        pageToken=next_page_token\n",
        "    )\n",
        "    response = request.execute()\n",
        "\n",
        "    for item in response['items']:\n",
        "        comment = item['snippet']['topLevelComment']['snippet']\n",
        "        comments.append([\n",
        "            comment['authorDisplayName'],\n",
        "            comment['publishedAt'],\n",
        "            comment['updatedAt'],\n",
        "            comment['likeCount'],\n",
        "            comment['textDisplay']\n",
        "        ])\n",
        "\n",
        "    # Check if there are more pages of comments\n",
        "    next_page_token = response.get('nextPageToken')\n",
        "    if not next_page_token:\n",
        "        break\n",
        "\n",
        "# Create a Pandas DataFrame from the comments list\n",
        "df = pd.DataFrame(comments, columns=['author', 'published_at', 'updated_at', 'like_count', 'text'])\n",
        "\n",
        "# Display the DataFrame\n",
        "print(df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jX4anLSLWFpk",
        "outputId": "76b99562-7948-4e62-efdf-869c679135ad"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                  author          published_at            updated_at  \\\n",
            "0         MAKHMUD GAMING  2023-11-01T09:57:04Z  2023-11-01T09:57:04Z   \n",
            "1                 jachuu  2023-11-01T09:54:42Z  2023-11-01T09:54:42Z   \n",
            "2           Canju Fatima  2023-11-01T09:44:38Z  2023-11-01T09:44:38Z   \n",
            "3             Sara Smith  2023-11-01T09:39:27Z  2023-11-01T09:39:27Z   \n",
            "4             Abdul aziz  2023-11-01T09:28:10Z  2023-11-01T09:28:10Z   \n",
            "...                  ...                   ...                   ...   \n",
            "3962           Alex Beal  2023-10-30T22:00:02Z  2023-10-30T22:00:02Z   \n",
            "3963             tvish10  2023-10-30T22:00:01Z  2023-10-30T22:00:01Z   \n",
            "3964        Laura Medina  2023-10-30T22:00:00Z  2023-10-30T22:00:00Z   \n",
            "3965  Unspeakable Nathan  2023-10-30T21:59:57Z  2023-10-30T22:00:34Z   \n",
            "3966      Lorena Zazueta  2023-10-30T21:59:54Z  2023-10-30T22:01:45Z   \n",
            "\n",
            "      like_count                                               text  \n",
            "0              0                                       Cry more ðŸ˜‚ðŸ˜‚ðŸ˜‚  \n",
            "1              0                                     Tumnus grumlin  \n",
            "2              3  <a href=\"https://www.youtube.com/watch?v=UZR1V...  \n",
            "3              0                                            1 53 10  \n",
            "4              0        Literally 1 day 1 crore in youtube views ðŸ˜®ðŸ˜®  \n",
            "...          ...                                                ...  \n",
            "3962           0                                              First  \n",
            "3963           2                                         It stopped  \n",
            "3964           0                                                Hhu  \n",
            "3965           4                                                2nd  \n",
            "3966           3                               W (Edit) FIRST!!! ðŸŽ‰â¤  \n",
            "\n",
            "[3967 rows x 5 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "comments= pd.DataFrame(df.iloc[:,-1])"
      ],
      "metadata": {
        "id": "2vxqWeHGWqgQ"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "csv_file_path = '/content/drive/MyDrive/dl/comments.csv'\n",
        "comments.to_csv(csv_file_path, index=False)\n",
        "print(f'DataFrame saved as {csv_file_path}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zK6apkjlPZns",
        "outputId": "d8a0e9ad-8607-4ec1-8de6-2bf7223695af"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame saved as /content/drive/MyDrive/dl/comments.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import googleapiclient.discovery\n",
        "import pandas as pd\n",
        "\n",
        "# Set your API key\n",
        "DEVELOPER_KEY = \"AIzaSyC0BmrSwtYtOnT78dBzgnbL3tp0RSpOwgg\"\n",
        "\n",
        "api_service_name = \"youtube\"\n",
        "api_version = \"v3\"\n",
        "\n",
        "youtube = googleapiclient.discovery.build(api_service_name, api_version, developerKey=DEVELOPER_KEY)\n",
        "\n",
        "# Initialize variables for pagination\n",
        "next_page_token = None\n",
        "comments = []\n",
        "\n",
        "while True:\n",
        "    request = youtube.commentThreads().list(\n",
        "        part=\"snippet\",\n",
        "        videoId=\"m7YSTtiPMl4\",  # Replace with the video ID you want to retrieve comments from\n",
        "        maxResults=100,  # Adjust the number of comments per page as needed\n",
        "        pageToken=next_page_token\n",
        "    )\n",
        "    response = request.execute()\n",
        "\n",
        "    for item in response['items']:\n",
        "        comment = item['snippet']['topLevelComment']['snippet']\n",
        "        comments.append([\n",
        "            comment['authorDisplayName'],\n",
        "            comment['publishedAt'],\n",
        "            comment['updatedAt'],\n",
        "            comment['likeCount'],\n",
        "            comment['textDisplay']\n",
        "        ])\n",
        "\n",
        "    # Check if there are more pages of comments\n",
        "    next_page_token = response.get('nextPageToken')\n",
        "    if not next_page_token:\n",
        "        break\n",
        "\n",
        "# Create a Pandas DataFrame from the comments list\n",
        "df = pd.DataFrame(comments, columns=['author', 'published_at', 'updated_at', 'like_count', 'text'])\n",
        "\n",
        "# Display the DataFrame\n",
        "print(df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jgGZnjrlnu04",
        "outputId": "17c8e022-e44d-4997-b3b9-2b35156ad5e1"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                 author          published_at            updated_at  \\\n",
            "0               Sidemen  2023-10-02T16:01:34Z  2023-10-06T23:03:56Z   \n",
            "1                 Macca  2023-11-01T11:14:54Z  2023-11-01T11:15:22Z   \n",
            "2                â˜…Demiâ˜…  2023-11-01T10:07:35Z  2023-11-01T10:07:35Z   \n",
            "3           Kamari Neal  2023-11-01T10:03:03Z  2023-11-01T10:08:22Z   \n",
            "4          Vedant Singh  2023-11-01T09:41:14Z  2023-11-01T09:41:14Z   \n",
            "...                 ...                   ...                   ...   \n",
            "37187  Noah O ' Riordan  2023-10-02T16:00:47Z  2023-10-02T16:00:47Z   \n",
            "37188              fear  2023-10-02T16:00:47Z  2023-10-02T16:00:54Z   \n",
            "37189    Phoebe Gardner  2023-10-02T16:00:47Z  2023-10-02T16:00:47Z   \n",
            "37190             Jayke  2023-10-02T16:00:47Z  2023-10-02T16:00:47Z   \n",
            "37191     Aarush Sawant  2023-10-02T16:00:46Z  2023-10-02T16:00:46Z   \n",
            "\n",
            "       like_count                                               text  \n",
            "0           51736  This is one we&#39;ve all been waiting for! En...  \n",
            "1               1  I don&#39;t know how no one has mentioned this...  \n",
            "2               0                                                ðŸ§¼ðŸ§¼ðŸ§¼  \n",
            "3               0  BRO I CAN&#39;T EVEN HOLD MY PHONE FROM LAUGHI...  \n",
            "4               0                              I want the white one!  \n",
            "...           ...                                                ...  \n",
            "37187           0                                              Forst  \n",
            "37188           0                                            SPEEEED  \n",
            "37189           0                                            Eeeeeee  \n",
            "37190           0                                                  1  \n",
            "37191           6                                              First  \n",
            "\n",
            "[37192 rows x 5 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "comments= pd.DataFrame(df.iloc[:,-1])"
      ],
      "metadata": {
        "id": "dW4q0kiCp4a_"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "csv_file_path = '/content/drive/MyDrive/dl/comments2.csv'\n",
        "comments.to_csv(csv_file_path, index=False)\n",
        "print(f'DataFrame saved as {csv_file_path}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QS-uIxD_oBOM",
        "outputId": "d493cb3f-0923-4c38-fdc1-e00f4d2de902"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame saved as /content/drive/MyDrive/dl/comments2.csv\n"
          ]
        }
      ]
    }
  ]
}